{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTED NECESSARY LIBRARIES"
      ],
      "metadata": {
        "id": "_GvaUTDf7ZZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv1D, MaxPooling1D, SimpleRNN, LeakyReLU, Dense, Dropout, Flatten, LSTM, GRU\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "fthVwzre1uTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "READ THE DATA"
      ],
      "metadata": {
        "id": "yUc2jjLw7hRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('df-rajendranagar - 4year.csv')\n",
        "#df = pd.read_csv('df-maruteru - 4year.csv')\n",
        "#df = pd.read_csv('df-raipur - 3year.csv')\n",
        "#df                                                                             #Uncomment to view the input dataset"
      ],
      "metadata": {
        "id": "D1982sf12JVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLIMATE FACTORS CALCULATED"
      ],
      "metadata": {
        "id": "rHovSAXS7vvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['LTP'] = round(df['ssh'] * ((df['max_t'] + df['min_t']) / 2), 2)\n",
        "df['TF'] = round(df['max_t'] - df['min_t'], 2)\n",
        "df['PTR'] = round(df['rf'] / (df['max_t'] + df['min_t']), 2)\n",
        "df['THC'] = round((df['rh1'] + df['rh2']) / (df['max_t'] + df['min_t']), 2)\n",
        "#df                                                                             #Uncomment to view the input dataset"
      ],
      "metadata": {
        "id": "jkh_0bww2Nbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DIFFERENCED COLUMNS CREATED FOR THE RESIDUALS"
      ],
      "metadata": {
        "id": "1dqed5FC73r0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_shifted = df.shift(1)\n",
        "for col in df.columns:\n",
        "    if col != 'date_time':  # Skip date_time column\n",
        "        col_diff = col + '_diff'\n",
        "        df[col_diff] = df[col] - df_shifted[col]\n",
        "        df[col_diff].fillna(0, inplace=True)  # Replace NaN values with 0\n",
        "#df                                                                             #Uncomment to view the input dataset"
      ],
      "metadata": {
        "id": "JlyUIV6V2T1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATE 1-LAG and 2-LAG TIME SHIFTED COLUMNS"
      ],
      "metadata": {
        "id": "W7aSOKCb7_Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_shift = df.columns[1:]\n",
        "for i in [1, 2]:\n",
        "    shifted_df = df[cols_to_shift].shift(i)\n",
        "    shifted_df.fillna(0, inplace=True)\n",
        "    shifted_df.columns = [f\"{col}+{i}\" for col in shifted_df.columns]\n",
        "    df = pd.concat([df, shifted_df], axis=1)\n",
        "#df                                                                             #Uncomment to view the input dataset"
      ],
      "metadata": {
        "id": "EjENDQoR2dfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.info()                                                                      #Uncomment to view the details of each column types and values"
      ],
      "metadata": {
        "id": "nhb-2rMB3tfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVERT TO DATETIME DATATYPE"
      ],
      "metadata": {
        "id": "OcnR_WJw8Nxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_time'] = pd.to_datetime(df['date_time'], infer_datetime_format=True)"
      ],
      "metadata": {
        "id": "I9WLCL6B3vGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CORRELATION MATRIX AND HEAT MAP FOR PEST WITH WEATHER"
      ],
      "metadata": {
        "id": "W_kRwPdX81E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation coefficients between the columns of the dataframe df\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Select the correlation values of the first column of the correlation matrix\n",
        "corr_with_first_col = corr_matrix.iloc[:, 0]\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10,20))\n",
        "\n",
        "# Generate a heatmap of the correlation values between the first column and all other columns\n",
        "sns.heatmap(pd.DataFrame(corr_with_first_col), cmap='coolwarm', annot=True)\n",
        "plt.title('Correlation with the First Column')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HJSvzQjl32BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVE UNRELATED COLUMNS - value 0.15 can be tuned to increase / decrease the number of columns being fed to the model for training"
      ],
      "metadata": {
        "id": "r-F1WdtH-nkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_input = df.iloc[:, 1:]     #df_input = df.iloc[:, 1:9]\n",
        "\n",
        "#Only select columns with high correlation with the pest\n",
        "high_corr_cols = corr_matrix.iloc[0][((corr_matrix.iloc[0] >= 0.15) | (corr_matrix.iloc[0] <= -0.15))].index.tolist()\n",
        "df_input = df[high_corr_cols]\n",
        "\n",
        "#df_input                                                                       #Uncomment to view the input dataset"
      ],
      "metadata": {
        "id": "g0ol9aNw7Jhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_input.describe()"
      ],
      "metadata": {
        "id": "UjMW-G0W7Mfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PEST DIFF and PEST LAG COLUMNS REMOVED, AS TARGET IS ONLY PEST AND INPUT IS ALL COLS EXCEPT PEST"
      ],
      "metadata": {
        "id": "Y43v-WsL_QPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['pest+1', 'pest+2', 'pest_diff', 'pest_diff+1', 'pest_diff+2']\n",
        "columns_existing = [col for col in columns_to_drop if col in df_input.columns]\n",
        "\n",
        "if columns_existing:\n",
        "    df_input.drop(columns_existing, axis=1, inplace=True)\n",
        "\n",
        "#df_input                                                                       #Uncomment to view the input dataset"
      ],
      "metadata": {
        "id": "kE-w5oMo7XSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PEST, PEST4W, PEST8W COLS CREATED AS TARGETS TO PREDICT 1, 4, 8 WEEKS INTO THE FUTURE"
      ],
      "metadata": {
        "id": "O4FjtOB1_ugu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame()\n",
        "df2['pest'] = df_input['pest'].copy()\n",
        "df_input['pest'] = df_input['pest'].shift(-1)\n",
        "df_input.insert(1, 'pest4w', df_input['pest'].shift(-3))\n",
        "df_input.insert(2, 'pest8w', df_input['pest4w'].shift(-4))\n",
        "\n",
        "df_input.loc[df_input.index[-1], 'pest'] = 0\n",
        "df_input.loc[df_input.index[-4:], 'pest4w'] = 0\n",
        "df_input.loc[df_input.index[-8:], 'pest8w'] = 0\n",
        "\n",
        "#df_input                                                                       #Uncomment to view the input dataset"
      ],
      "metadata": {
        "id": "Ct_P8ItD7fDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMALIZE THE DATA USING MIN MAX SCALER"
      ],
      "metadata": {
        "id": "sA3QBKEP_pbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and Normalizing\n",
        "scaler = MinMaxScaler()  # Create a MinMaxScaler object\n",
        "\n",
        "print(df_input.shape)  # Print the shape of the original DataFrame\n",
        "\n",
        "# Compute the min and max values of each column of df_input and scale the values of each column to the range [0, 1]\n",
        "# Assign the scaled data to the variable data_scaled\n",
        "data_scaled = scaler.fit_transform(df_input)\n",
        "\n",
        "# Print the resulting shape of the scaled data\n",
        "print(data_scaled.shape)\n",
        "\n",
        "#data_scaled                                                                    #Uncomment Print the scaled data"
      ],
      "metadata": {
        "id": "4SON6zOW7gwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WEATHER PARAMETERS ADDED TO INPUT AND PEST TO TARGET"
      ],
      "metadata": {
        "id": "E6SSqWcCAgu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#INPUT\n",
        "features = data_scaled[:, 3:]               #This takes all the columns as input expect the pest column\n",
        "\n",
        "#TARGET\n",
        "target = data_scaled[:, 0:3]\n",
        "\n",
        "print(features.shape)\n",
        "print(target.shape)"
      ],
      "metadata": {
        "id": "MgGyyeZt7iVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET SPLIT INTO TRAINING VALIDATION AND TESTING"
      ],
      "metadata": {
        "id": "gVM-XHtoAlJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the input data and target data into training, validation and testing sets.\n",
        "\n",
        "test_size = 52 / len(features) # calculate the test size as a fraction of the total rows\n",
        "x_train_val, x_test, y_train_val, y_test = train_test_split(features, target, test_size=test_size, shuffle=False)\n",
        "\n",
        "train_size = 0.9 # set the size of the train set as a fraction of the remaining rows\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, train_size=train_size, shuffle=False)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "0f1qFmhC7lBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WINDOW LENGTH CAN BE MODIFIED BASED ON REQUIREMENT (WE TRIED WITH 4 and 2 Weeks as inputs)\n",
        "KERNEL SIZE OF MAX POOL LAYER OF 1D CNN WILL DEPEND ON THE WIN_LENGTH"
      ],
      "metadata": {
        "id": "7A3vsDOhAuro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "win_length = 4                                                      #win_length = int(x_train.shape[0] / 32)        #win_length=8\n",
        "batch_size = int(x_train.shape[0] / 4)                             #batch_size=4\n",
        "num_features = x_train.shape[1]                                     #num_features=8 #This is to be selected based on columns of input\n",
        "train_generator = TimeseriesGenerator(x_train, y_train, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
        "val_generator = TimeseriesGenerator(x_val, y_val, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
        "test_generator = TimeseriesGenerator(x_test, y_test, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
        "print(win_length)\n",
        "print(batch_size)\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "kxWAbgqY7mWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FROM MODEL A/B, C/D, E/F - KEEP ONLY 1 CODE ACTIVE\n",
        ">>> USE KERNEL SIZE = 3 and POOL SIZE = 2 FOR WINDOW LENGTH = 4\n",
        ">>> USE KERNEL SIZE = 2 and POOL SIZE = 1 FOR WINDOW LENGHT = 2\n",
        ">>>>> FOR OTHER WINDOW SIZE USE APPROPRIATE KERNEL AND POOL SIZE"
      ],
      "metadata": {
        "id": "jRb8-A02Canf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONLY MODEL A OR MODEL B TO BE SELECTED\n",
        "1.   MODEL A: CNN-RNN (UNCOMMENT CNN LAYERS AND COMMENT THE FIRST RNN LAYER)\n",
        "2.   MODEL B: RNN (COMMENT CNN LAYERS AND UNCOMMENT THE FIRST RNN LAYER)"
      ],
      "metadata": {
        "id": "wwV31WZJA7y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "#KEEP NEXT 3 LINES FOR THE MODEL A\n",
        "# CNN Layers\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(win_length, num_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "#KEEP NEXT 3 LINES FOR THE MODEL B\n",
        "# # RNN Layers\n",
        "# model.add(SimpleRNN(32, return_sequences=True, input_shape=(win_length, num_features)))\n",
        "# model.add(LeakyReLU())\n",
        "\n",
        "#NO CHANGE IN BELOW CODE\n",
        "# RNN Layers\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(LeakyReLU())\n",
        "\n",
        "# Dense Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Ahj6RnBQ7p-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONLY MODEL C OR MODEL D TO BE SELECTED\n",
        "1.   MODEL C: CNN-LSTM (UNCOMMENT CNN LAYERS AND COMMENT THE FIRST LSTM LAYER)\n",
        "2.   MODEL D: LSTM (COMMENT CNN LAYERS AND UNCOMMENT THE FIRST LSTM LAYER)"
      ],
      "metadata": {
        "id": "3GNzLT4WCC_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create the sequential model\n",
        "# model = Sequential()\n",
        "\n",
        "# #KEEP NEXT 3 LINES FOR THE MODEL C\n",
        "# #CNN Layers\n",
        "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(win_length, num_features)))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# #KEEP NEXT 3 LINES FOR THE MODEL D\n",
        "# # #LSTM Layers\n",
        "# # model.add(LSTM(32, return_sequences=True, input_shape=(win_length, num_features)))\n",
        "# # model.add(LeakyReLU())\n",
        "\n",
        "# #LSTM Layers\n",
        "# model.add(LSTM(32, return_sequences=True))\n",
        "# model.add(LeakyReLU())\n",
        "\n",
        "# #Dense Layers\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(3, activation='relu'))\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "AnZzlAzpCKXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONLY MODEL E OR MODEL F TO BE SELECTED\n",
        "1.   MODEL E: CNN-GRU (UNCOMMENT CNN LAYERS AND COMMENT THE FIRST GRU LAYER)\n",
        "2.   MODEL F: GRU (COMMENT CNN LAYERS AND UNCOMMENT THE FIRST GRU LAYER)"
      ],
      "metadata": {
        "id": "lp9psT5ECoUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create the sequential model\n",
        "# model = Sequential()\n",
        "\n",
        "# #KEEP NEXT 3 LINES FOR THE MODEL E\n",
        "# #CNN Layers\n",
        "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(win_length, num_features)))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# #KEEP NEXT 3 LINES FOR THE MODEL F\n",
        "# # #GRU Layers\n",
        "# # model.add(GRU(32, return_sequences=True, input_shape=(win_length, num_features)))\n",
        "# # model.add(LeakyReLU())\n",
        "\n",
        "# #GRU Layers\n",
        "# model.add(GRU(32, return_sequences=True))\n",
        "# model.add(LeakyReLU())\n",
        "\n",
        "# #Dense Layers\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(3, activation='relu'))\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "7v6SfTETCo7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL FITTING"
      ],
      "metadata": {
        "id": "pERTes2YEqLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = 'model_best.h5'\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,save_best_only=True,monitor='val_loss',mode='min',verbose=0)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
        "history = model.fit(train_generator, epochs=300, validation_data=val_generator,callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "hIiphNvi7vUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lowest Validation Epoch is considered for the model training\n",
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Training vs Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "\n",
        "# add a vertical line to mark the epoch with the lowest validation loss\n",
        "plt.axvline(x=best_epoch, color='r', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q_4XeIef7zkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL ARCHITECTURE"
      ],
      "metadata": {
        "id": "Gsjx3dUjEvVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, show_dtype=False, show_layer_names=True, rankdir=\"TB\", expand_nested=True, dpi=96, layer_range=None, show_layer_activations=True)"
      ],
      "metadata": {
        "id": "tYPUAIWy71ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICT FROM THE TEST"
      ],
      "metadata": {
        "id": "8YUmIlgyEyMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator, verbose=0)\n",
        "predictions=model.predict(test_generator)\n",
        "predictions.shape[0]\n",
        "\n",
        "#print(predictions)                                                             #Uncomment to check for values\n",
        "#print(predictions.shape)                                                       #Uncomment to check for values"
      ],
      "metadata": {
        "id": "4-F8_ehB73Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "POST PROCESSING TO BRING DATA BACK TO ACTUAL VALUES"
      ],
      "metadata": {
        "id": "6V7A3a5xE2N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred=pd.concat([pd.DataFrame(predictions), pd.DataFrame(x_test[win_length:])],axis=1)\n",
        "df_pred\n",
        "print(df_pred.shape)"
      ],
      "metadata": {
        "id": "5seVD4X477qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rev_trans=scaler.inverse_transform(df_pred) #X = X_scaled * (X_max - X_min) + X_min"
      ],
      "metadata": {
        "id": "zxOjCHvU7-oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final=df_input[predictions.shape[0]*-1:]\n",
        "df_final.count()"
      ],
      "metadata": {
        "id": "VUIWxRuZ-hQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final['prediction']=rev_trans[:,0]\n",
        "df_final['prediction-4w']=rev_trans[:,1]\n",
        "df_final['prediction-8w']=rev_trans[:,2]"
      ],
      "metadata": {
        "id": "Y-VpzEEd8AGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final\n",
        "\n",
        "df_final['prediction-4w'] = df_final['prediction-4w'].shift(4)\n",
        "df_final['prediction-4w'].iloc[:4] = 0\n",
        "\n",
        "df_final['prediction-8w'] = df_final['prediction-8w'].shift(8)\n",
        "df_final['prediction-8w'].iloc[:8] = 0"
      ],
      "metadata": {
        "id": "qmzlfoiZ8GOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final['pest'] = df2['pest']\n",
        "df_final_forresult = df_final\n",
        "df_final_forresult"
      ],
      "metadata": {
        "id": "Bduh8FmJ_dxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LONG-TERM (52 WEEK) PREDICTION PLOT"
      ],
      "metadata": {
        "id": "BR2k1oUmE_eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_forresult = df_final.copy()\n",
        "\n",
        "fig, axs = plt.subplots(figsize=(10, 7))\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['pest'], label='Actual', marker='o', s=50)\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['prediction'], label='Prediction', marker='o', s=50)\n",
        "axs.set_title('Pest vs Prediction')\n",
        "axs.set_xlabel('Week (No.)')\n",
        "axs.set_ylabel('Pest (No.s)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7, which='both')\n",
        "legend = plt.legend(fontsize='medium')\n",
        "for legend_handle in legend.legendHandles:\n",
        "    legend_handle.set_sizes([50])  # Adjust marker size\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.margins(0.05)\n",
        "plt.show()\n",
        "\n",
        "mse = mean_squared_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "r2 = r2_score(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "mae = mean_absolute_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "print(f\"RMSE: {round(rmse, 2)}; R2: {round(r2, 2)}; MAE: {round(mae, 2)}\")"
      ],
      "metadata": {
        "id": "6UzQAw1_8JRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHORT-TERM (4 WEEK) PREDICTION PLOT"
      ],
      "metadata": {
        "id": "HWiXeBJXFCxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_forresult = df_final.copy()\n",
        "df_final_forresult.drop(df_final_forresult.index[4:], inplace=True)\n",
        "\n",
        "fig, axs = plt.subplots(figsize=(10, 7))\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['pest'], label='Actual', marker='o', s=50)\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['prediction'], label='Prediction', marker='o', s=50)\n",
        "axs.set_title('Pest vs Prediction')\n",
        "axs.set_xlabel('Week (No.)')\n",
        "axs.set_ylabel('Pest (No.s)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7, which='both')\n",
        "legend = plt.legend(fontsize='medium')\n",
        "for legend_handle in legend.legendHandles:\n",
        "    legend_handle.set_sizes([50])  # Adjust marker size\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.margins(0.05)\n",
        "plt.show()\n",
        "\n",
        "mse = mean_squared_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "r2 = r2_score(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "mae = mean_absolute_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "print(f\"RMSE: {round(rmse, 2)}; R2: {round(r2, 2)}; MAE: {round(mae, 2)}\")"
      ],
      "metadata": {
        "id": "SkD5LM-L8y30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONSOLIDATED PLOTS FROM ABOVE"
      ],
      "metadata": {
        "id": "X2KdwI9NFFYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "\n",
        "plt.figure(figsize=(8, 12), dpi=150)  # Set figsize and DPI\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Training vs Validation Loss')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.axvline(x=best_epoch, color='r', linestyle='--')\n",
        "\n",
        "df_final_forresult = df_final.copy()\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['pest'], label='Actual', marker='o', s=50)\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['prediction'], label='Prediction', marker='o', s=50)\n",
        "plt.title('Pest vs Prediction')\n",
        "plt.xlabel('Week (No.)')\n",
        "plt.ylabel('Pest (No.s)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7, which='both')\n",
        "legend = plt.legend(fontsize='medium')\n",
        "for legend_handle in legend.legendHandles:\n",
        "    legend_handle.set_sizes([50])  # Adjust marker size\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.margins(0.05)\n",
        "\n",
        "mse_b = mean_squared_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "rmse_b = np.sqrt(mse_b)\n",
        "mae_b = mean_absolute_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "r2_b = r2_score(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "metrics_b = f\"RMSE: {round(rmse_b, 2)}; R2: {round(r2_b, 2)}; MAE: {round(mae_b, 2)}\"\n",
        "plt.text(0.5, -0.2, metrics_b, transform=plt.gca().transAxes, fontsize=10, ha='center')\n",
        "\n",
        "df_final_forresult.drop(df_final_forresult.index[4:], inplace=True)\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['pest'], label='Actual', marker='o', s=50)\n",
        "plt.scatter(df_final_forresult.index, df_final_forresult['prediction'], label='Prediction', marker='o', s=50)\n",
        "plt.title('Pest vs Prediction')\n",
        "plt.xlabel('Week (No.)')\n",
        "plt.ylabel('Pest (No.s)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7, which='both')\n",
        "legend = plt.legend(fontsize='medium')\n",
        "for legend_handle in legend.legendHandles:\n",
        "    legend_handle.set_sizes([50])  # Adjust marker size\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.margins(0.05)\n",
        "\n",
        "mse_c = mean_squared_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "rmse_c = np.sqrt(mse_c)\n",
        "mae_c = mean_absolute_error(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "r2_c = r2_score(df_final_forresult['pest'], df_final_forresult['prediction'])\n",
        "metrics_c = f\"RMSE: {round(rmse_c, 2)}; R2: {round(r2_c, 2)}; MAE: {round(mae_c, 2)}\"\n",
        "plt.text(0.5, -0.2, metrics_c, transform=plt.gca().transAxes, fontsize=10, ha='center')\n",
        "\n",
        "# Adjust subplot spacing\n",
        "plt.tight_layout(pad=2)\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('model_performance_plot.png', dpi=150, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eHfCI4_soyYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}